# ğŸ§  Prompt Injection & Giskard ğŸ¢

## ğŸ‡¬ğŸ‡§ English Version

### Overview

This repository contains the course project on prompt injection attacks and LLM (Large Language Model) security, created in collaboration with a classmate. The presentation explains how the open-source tool **Giskard** ğŸ¢ can be used to detect and prevent prompt injection vulnerabilities in AI systems.

### Project Content

- ğŸ–¼ï¸ A slide deck (`.pptx`, `.pdf`) detailing the concept of prompt injection and how Giskard mitigates such risks.

### Technologies & Skills

- Prompt Injection Attacks
- LLM Security & Ethics
- Giskard ğŸ¢ (open-source testing framework)

---

## ğŸ‡«ğŸ‡· Version FranÃ§aise

### PrÃ©sentation

Ce dÃ©pÃ´t contient un projet de cours rÃ©alisÃ© avec un camarade sur les attaques par **prompt injection** et la sÃ©curitÃ© des modÃ¨les de langage (LLM). La prÃ©sentation met en lumiÃ¨re comment lâ€™outil open source **Giskard** ğŸ¢ permet dâ€™identifier et de prÃ©venir ces vulnÃ©rabilitÃ©s.

### Contenu du Projet

- ğŸ–¼ï¸ Une prÃ©sentation PowerPoint, Pdf sur le prompt injection et les solutions proposÃ©es par Giskard.

### Technologies & CompÃ©tences

- Attaques par Prompt Injection
- SÃ©curitÃ© & Ã‰thique des LLM
- Giskard ğŸ¢ (framework open source de tests)
